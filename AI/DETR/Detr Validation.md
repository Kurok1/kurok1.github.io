
# å•ä¸ªIoU


> æ¯”è¾ƒæ£€æµ‹ç»“æœçš„é¢ç§¯å’Œå·²ç»æ ‡æ³¨çš„é¢ç§¯äº¤å‰éƒ¨åˆ†çš„å æ¯”

IoUå®šä¹‰ï¼š
 $$\text{IoU} = \frac{é¢„æµ‹æ¡† âˆ© æ ‡æ³¨æ¡†}{é¢„æµ‹æ¡† âˆª æ ‡æ³¨æ¡†}  $$


---

æ¨èæµç¨‹å¦‚ä¸‹ï¼š

Step 1ï¼šä¸€ä¸€åŒ¹é…é¢„æµ‹æ¡†å’Œ GT æ¡†

- é€šå¸¸ç”¨ **æœ€å¤§ IoU åŒ¹é…**
    
- ä¸€ä¸ª GT åªèƒ½åŒ¹é…ä¸€ä¸ªé¢„æµ‹æ¡†
    

Step 2ï¼šè®¡ç®— IoU

```python
iou = inter_area / union_area
```

Step 3ï¼šè®¾å®šé˜ˆå€¼

```text
IoU â‰¥ 0.5 â†’ True Positive
IoU < 0.5 â†’ False Positive
GT æ²¡è¢«åŒ¹é… â†’ False Negative
```


---

## éªŒè¯æµç¨‹

- å‡†å¤‡åŸå§‹å›¾ç‰‡å’Œcocoæ ¼å¼çš„å›¾ç‰‡
cocoæ ¼å¼å‚æ•°å¦‚ä¸‹ï¼š
```json
{
  "images": [{"id": 1, "file_name": "test.jpg"}],
  "annotations": [
    {
      "image_id": 1,
      "bbox": [x, y, w, h],
      "category_id": 3
    }
  ]
}

```

å‡è®¾detræ¨¡å‹é¢„æµ‹æ ¼å¼å¦‚ä¸‹ï¼š
```json
predictions = [
    {
        "bbox": [x1, y1, x2, y2],  # æ³¨æ„ï¼šxyxy
        "score": 0.92,
        "category_id": 3
    }
]

```

- è®¡ç®—ä¸¤ä¸ªbboxçš„IoU
```python
def compute_iou(box1, box2):
    """
    box: [x1, y1, x2, y2]
    """
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    inter_w = max(0, x2 - x1)
    inter_h = max(0, y2 - y1)
    inter_area = inter_w * inter_h

    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])

    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

```
- ä»å•ä¸ªcocoæ ¼å¼æ–‡ä»¶ä¸­è¯»å–bboxå’Œlabels
```python
import json

def load_coco_gt(coco_json_path, image_id):
    with open(coco_json_path, "r") as f:
        coco = json.load(f)

    gt_boxes = []
    gt_labels = []

    for ann in coco["annotations"]:
        if ann["image_id"] == image_id:
            x, y, w, h = ann["bbox"]
            gt_boxes.append([x, y, x + w, y + h])  # è½¬ xyxy
            gt_labels.append(ann["category_id"])

    return gt_boxes, gt_labels

```
- IoU åŒ¹é… + TP/FP/FN ç»Ÿè®¡
```python
"""
TPï¼šTrue Positiveï¼Œåˆ†ç±»å™¨é¢„æµ‹ç»“æœä¸ºæ­£æ ·æœ¬ï¼Œå®é™…ä¹Ÿä¸ºæ­£æ ·æœ¬ï¼Œå³æ­£æ ·æœ¬è¢«æ­£ç¡®è¯†åˆ«çš„æ•°é‡ã€‚
FPï¼šFalse Positiveï¼Œåˆ†ç±»å™¨é¢„æµ‹ç»“æœä¸ºæ­£æ ·æœ¬ï¼Œå®é™…ä¸ºè´Ÿæ ·æœ¬ï¼Œå³è¯¯æŠ¥çš„è´Ÿæ ·æœ¬æ•°é‡ã€‚
FNï¼šFalse Negativeï¼Œåˆ†ç±»å™¨é¢„æµ‹ç»“æœä¸ºè´Ÿæ ·æœ¬ï¼Œå®é™…ä¸ºæ­£æ ·æœ¬ï¼Œå³æ¼æŠ¥çš„æ­£æ ·æœ¬æ•°é‡ã€‚
"""
def evaluate_single_image(gt_boxes, gt_labels, preds, iou_thresh=0.5):
    matched_gt = set()
    results = []

    for pred in preds:
        best_iou = 0
        best_gt_idx = -1

        for i, gt_box in enumerate(gt_boxes):
            if i in matched_gt:
                continue
            if pred["category_id"] != gt_labels[i]:
                continue

            iou = compute_iou(pred["bbox"], gt_box)
            if iou > best_iou:
                best_iou = iou
                best_gt_idx = i

        if best_iou >= iou_thresh:
            matched_gt.add(best_gt_idx)
            results.append(("TP", best_iou))
        else:
            results.append(("FP", best_iou))

    fn = len(gt_boxes) - len(matched_gt)
    return results, fn

```
- è°ƒç”¨å‚è€ƒ
```python
# COCO æ ‡æ³¨
coco_json = "annotations.json"
image_id = 1

gt_boxes, gt_labels = load_coco_gt(coco_json, image_id)

# æ¨¡å‹é¢„æµ‹ï¼ˆç¤ºä¾‹ï¼‰
predictions = [
    {
        "bbox": [100, 120, 220, 260],  # xyxy
        "score": 0.9,
        "category_id": 3
    }
]

# ç½®ä¿¡åº¦è¿‡æ»¤
predictions = [p for p in predictions if p["score"] > 0.5]

results, fn = evaluate_single_image(gt_boxes, gt_labels, predictions)

print("Results:")
for r in results:
    print(r)

print("False Negatives:", fn)

#ç»“æœå¯èƒ½å¦‚ä¸‹
("TP", 0.73)   # æ­£ç¡®æ£€æµ‹ï¼ŒIoU=0.73
("FP", 0.12)   # é¢„æµ‹é”™è¯¯
False Negatives: 1
```


# mAPè¯„ä¼°

## ä¸€ã€æ•´ä½“è¯„ä¼°æµç¨‹ï¼ˆå…ˆå¯¹é½æ¦‚å¿µï¼‰

ä½ è¦åšçš„ **æ•´ä½“ mAP è¯„ä¼°**ï¼Œæœ¬è´¨æ˜¯ï¼š

> ç”¨ **COCO å®˜æ–¹è¯„ä¼°é€»è¾‘**ï¼š
> åœ¨ **æ•´ä¸ªéªŒè¯é›†** ä¸Šç»Ÿè®¡ **å¤š IoU é˜ˆå€¼ + å¤šç±»åˆ«** çš„ Precision-Recallï¼Œå¾—åˆ° mAP

æ ‡å‡†æµç¨‹å¦‚ä¸‹ï¼š

```
GTï¼ˆCOCOæ ¼å¼ï¼‰
        â†“
æ¨¡å‹é¢„æµ‹æ‰€æœ‰å›¾ç‰‡
        â†“
æ•´ç†æˆ COCO detection æ ¼å¼ï¼ˆpred.jsonï¼‰
        â†“
COCOeval
        â†“
mAP / AP50 / AP75 / Recall
```

ğŸ‘‰ **å¼ºçƒˆå»ºè®®**ï¼šä¸è¦è‡ªå·±æ‰‹å†™ mAPï¼Œç›´æ¥ç”¨ `pycocotools`

---

## äºŒã€éœ€è¦å‡†å¤‡çš„ 2 ä¸ªæ–‡ä»¶

Ground Truthï¼ˆä½ å·²ç»æœ‰ï¼‰

COCO åŸå§‹æ ‡æ³¨æ–‡ä»¶ï¼Œä¾‹å¦‚ï¼š

```text
instances_val.json
```

---

Detection Resultsï¼ˆä½ éœ€è¦ç”Ÿæˆï¼‰

è¿™æ˜¯ä¸€ä¸ª **list of dict**ï¼Œæ ¼å¼**éå¸¸ä¸¥æ ¼**ï¼š

```json
[
  {
    "image_id": 1,
    "category_id": 3,
    "bbox": [x, y, w, h],
    "score": 0.92
  }
]
```

âš ï¸ æ³¨æ„ï¼š

- bbox å¿…é¡»æ˜¯ **xywh**
    
- image_id / category_id **å¿…é¡»å’Œ GT ä¸€è‡´**
    
- score æ˜¯ç½®ä¿¡åº¦
    

---

## ä¸‰ã€ä» DETR è¾“å‡ºç”Ÿæˆ COCO Detection ç»“æœ

å‡è®¾ DETR è¾“å‡ºï¼ˆå•å¼ å›¾ï¼‰ï¼š

```python
outputs = {
    "boxes": Tensor[N, 4],   # xyxy
    "scores": Tensor[N],
    "labels": Tensor[N]
}
```

---

 âœ… DETR â†’ COCO bbox è½¬æ¢ï¼ˆå¯é€‰å®ç°,æœ¬åœ°ç¦»çº¿æ¨ç†ä½¿ç”¨ï¼‰

```python
def detr_to_coco(preds, image_id, score_thresh=0.8):
	"""
	åœ¨çº¿detræ¨ç†ç›´æ¥è°ƒç”¨åœ¨çº¿æœåŠ¡å³å¯
	"""
    results = []

    for box, score, label in zip(
        preds["boxes"], preds["scores"], preds["labels"]
    ):
        if score < score_thresh:
            continue

        x1, y1, x2, y2 = box.tolist()
        w = x2 - x1
        h = y2 - y1

        results.append({
            "image_id": image_id,
            "category_id": int(label),
            "bbox": [x1, y1, w, h],
            "score": float(score)
        })

    return results
```

---

âœ… éå†æ•´ä¸ªéªŒè¯é›†

```python
all_results = []

for image_id, image in dataloader:
    preds = model(image)

    coco_preds = detr_to_coco(preds, image_id)
    all_results.extend(coco_preds)
```

---

âœ… ä¿å­˜ä¸º json

```python
import json

with open("detr_results.json", "w") as f:
    json.dump(all_results, f)
```

---


## å››ã€DETR è¯„ä¼°ä¸­çš„ 4 ä¸ªå¸¸è§å‘ï¼ˆä¸€å®šè¦æ£€æŸ¥ï¼‰

âŒ 1. bbox åæ ‡æ ¼å¼é”™

- GTï¼š`xywh`
    
- DETR è¾“å‡ºï¼š`xyxy`
    
- **ä¸€å®šè¦è½¬**
    

---

âŒ 2. category_id å¯¹ä¸ä¸Š

- COCO category_id **ä¸æ˜¯è¿ç»­çš„**
    
- å¦‚æœä½ æ˜¯è‡ªå®šä¹‰æ•°æ®é›†ï¼š
    

```python
label â†’ coco_category_id
```

è¦æ˜¾å¼æ˜ å°„

---

âŒ 3. image_id ä¸ä¸€è‡´

- image_id **å¿…é¡»æ˜¯ COCO æ ‡æ³¨é‡Œçš„ id**
    
- ä¸æ˜¯æ–‡ä»¶åï¼Œä¸æ˜¯ index
    

---

âŒ 5. ç”¨å•å¼ å›¾åˆ¤æ–­æ¨¡å‹å¥½å

- mAP **å¿…é¡»æ˜¯æ•°æ®é›†çº§åˆ«**
    
- å•å¼ å›¾åªèƒ½ debug

# mAPæ¨å¯¼è¿‡ç¨‹
DETR åœ¨è®ºæ–‡/ä»£ç é‡ŒæŠ¥å‘Šçš„ **mAP**ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯ç”¨ **COCO å®˜æ–¹è¯„æµ‹ï¼ˆpycocotools/COCOevalï¼‰**ç®—å‡ºæ¥çš„ AP æŒ‡æ ‡ï¼ˆå¸¸è§å†™æ³• **AP@[0.50:0.95]**ï¼‰ã€‚DETR åªæ˜¯â€œæ€ä¹ˆäº§ç”Ÿé¢„æµ‹æ¡†â€çš„æ–¹å¼ä¸åŒï¼ˆset predictionã€é€šå¸¸ä¸åš NMSï¼‰ï¼Œ**è¯„æµ‹æ—¶ä» IoU åˆ° mAP çš„è®¡ç®—æµç¨‹å’Œå…¶ä»–æ£€æµ‹å™¨æ˜¯ä¸€æ ·çš„**ã€‚([GitHub](https://raw.githubusercontent.com/facebookresearch/detr/main/README.md "raw.githubusercontent.com"))

ä¸‹é¢æŒ‰â€œä» IoU ä¸€æ­¥æ­¥åˆ° mAPâ€è®²æ¸…æ¥šï¼Œå¹¶é…ä¸Šå…¬å¼ã€‚

---

## 1) IoUï¼šä»æ¡†çš„é‡å å¼€å§‹

å¯¹ä»»æ„ä¸€ä¸ªé¢„æµ‹æ¡† (b) å’Œä¸€ä¸ª GT æ¡† (g)ï¼Œå®šä¹‰

$$
\mathrm{IoU}(b,g)=\frac{|b\cap g|}{|b\cup g|}.  
$$

IoU æ˜¯åé¢åˆ¤å®šâ€œè¿™ä¸ªé¢„æµ‹ç®—ä¸ç®—å‘½ä¸­ï¼ˆTPï¼‰â€çš„æ ¸å¿ƒä¾æ®ã€‚

---

## 2) é€‰å®š IoU é˜ˆå€¼ï¼šCOCO ä¸æ˜¯åªç”¨ 0.5

COCO çš„ä¸»æŒ‡æ ‡ä¼šåœ¨ **10 ä¸ª IoU é˜ˆå€¼**ä¸Šéƒ½ç®—ä¸€é APï¼Œç„¶åå†å¹³å‡ï¼š

$$  
T={0.50,0.55,\dots,0.95}\quad(\Delta=0.05).  
$$

COCOeval é‡Œå°±å†™ç€é»˜è®¤ **iouThrs = [.5:.05:.95]ï¼ŒT=10**ã€‚([Hugging Face](https://huggingface.co/spaces/sklum/detection_metrics/blob/3e2a0ca16993a7736a7b61f4281c2151a2eb406a/cocoeval.py "cocoeval.py Â· sklum/detection_metrics at 3e2a0ca16993a7736a7b61f4281c2151a2eb406a"))

---

## 3) åœ¨æ¯ä¸ªç±»åˆ«ã€æ¯ä¸ªé˜ˆå€¼ä¸‹ï¼šç”¨ IoU åšâ€œåŒ¹é…â€ â†’ å¾—åˆ° TP/FP

å¯¹æ¯ä¸ªç±»åˆ« $(c)$ï¼ˆCOCO æ˜¯æŒ‰ç±»ç®— APï¼Œå†å¹³å‡ï¼‰ï¼Œåœ¨æŸä¸ª IoU é˜ˆå€¼ $(t\in T)$ ä¸‹ï¼š

1. æ”¶é›†è¯¥ç±»åˆ«çš„æ‰€æœ‰é¢„æµ‹æ¡† $({(b_i, s_i)})$ï¼Œå…¶ä¸­ $(s_i)$ æ˜¯ç½®ä¿¡åº¦ï¼ˆDETR çš„åˆ†ç±»æ¦‚ç‡/scoreï¼‰ã€‚
    
2. **æŒ‰ score ä»é«˜åˆ°ä½æ’åº**ã€‚
    
3. é€ä¸ªé¢„æµ‹æ¡† (b_i) å»åŒ¹é…åŒä¸€å¼ å›¾ã€åŒä¸€ç±»åˆ«é‡Œâ€œå°šæœªè¢«åŒ¹é…è¿‡â€çš„ GT æ¡†ï¼Œæ‰¾ IoU æœ€å¤§çš„é‚£ä¸ªï¼š  
    $$  
    g^*(i)=\arg\max_{g\in \mathcal{G}_{\text{unmatched}}}\mathrm{IoU}(b_i,g)  
    $$
    
    - è‹¥ $(\max \mathrm{IoU}(b_i,g)\ge t)$ï¼Œåˆ™ $(b_i)$ æ˜¯ **TP**ï¼Œå¹¶æŠŠå¯¹åº” GT æ ‡è®°ä¸ºå·²åŒ¹é…ï¼ˆä¸€ä¸ª GT åªèƒ½åŒ¹é…ä¸€æ¬¡ï¼‰ã€‚
        
    - å¦åˆ™ $(b_i)$ æ˜¯ **FP**ã€‚
        

> COCO è¯„æµ‹è¿˜ä¼šå¯¹æ¯å¼ å›¾æœ€å¤šå–å‰ (100) ä¸ªæ£€æµ‹ï¼ˆmaxDets é»˜è®¤æ˜¯ ([1,10,100])ï¼‰ï¼Œé€šå¸¸å¤§å®¶æŠ¥å‘Šçš„æ¡† AP ç”¨çš„æ˜¯ maxDet=100 é‚£æ¡£ã€‚([Hugging Face](https://huggingface.co/spaces/sklum/detection_metrics/blob/3e2a0ca16993a7736a7b61f4281c2151a2eb406a/cocoeval.py "cocoeval.py Â· sklum/detection_metrics at 3e2a0ca16993a7736a7b61f4281c2151a2eb406a"))

---

## 4) ç”¨ TP/FP åºåˆ—æ„é€  Precisionâ€“Recall æ›²çº¿

è®¾è¯¥ç±»åˆ«åœ¨å…¨æ•°æ®é›†é‡Œ GT æ€»æ•°ä¸º $(N_{\text{gt}})$ ã€‚å¯¹æ’åºåçš„é¢„æµ‹ä» 1 åˆ° (k) åšç´¯ç§¯ï¼š

$$  
\mathrm{TP}(k)=\sum_{i=1}^{k}\mathbf{1}[i\text{ is TP}],\qquad  
\mathrm{FP}(k)=\sum_{i=1}^{k}\mathbf{1}[i\text{ is FP}]  
$$

åˆ™

$$  
\mathrm{Precision}(k)=\frac{\mathrm{TP}(k)}{\mathrm{TP}(k)+\mathrm{FP}(k)},\qquad  
\mathrm{Recall}(k)=\frac{\mathrm{TP}(k)}{N_{\text{gt}}}.  
$$

å½“ä½ ä»é«˜åˆ†åˆ°ä½åˆ†ä¸æ–­â€œæ”¾å®½é˜ˆå€¼â€ï¼ˆç­‰ä»·äºå–æ›´é•¿çš„å‰ç¼€ (k)ï¼‰ï¼Œå°±å¾—åˆ°ä¸€æ¡ PR æ›²çº¿ã€‚

---

## 5) æ’å€¼ï¼ˆinterpolated precisionï¼‰ï¼šæŠŠ PR æ›²çº¿â€œæŠ¹å¹³â€

COCO ä½¿ç”¨ **101 ä¸ª recall é‡‡æ ·ç‚¹**ï¼š

$$  
R={0,0.01,0.02,\dots,1.00}\quad(|R|=101),  
$$

COCOeval é‡Œå†™çš„é»˜è®¤å°±æ˜¯ **recThrs = [0:.01:1]ï¼ŒR=101**ã€‚([Hugging Face](https://huggingface.co/spaces/sklum/detection_metrics/blob/3e2a0ca16993a7736a7b61f4281c2151a2eb406a/cocoeval.py "cocoeval.py Â· sklum/detection_metrics at 3e2a0ca16993a7736a7b61f4281c2151a2eb406a"))

å¯¹æ¯ä¸ªé‡‡æ · recall å€¼ $(r\in R)$ï¼ŒCOCO ç”¨â€œå‘å³å–æœ€å¤§â€çš„æ’å€¼ç²¾åº¦ï¼ˆä¿è¯ç²¾åº¦éš recall å•è°ƒä¸å¢ï¼‰ï¼š

$$  
\hat p(r)=\max_{\tilde r\ge r} p(\tilde r),  
$$

å…¶ä¸­ $(p(\tilde r))$ æ˜¯åŸå§‹ PR æ›²çº¿ä¸Šå¯¹åº” recall å¤„çš„ precisionï¼ˆå®ç°ä¸Šæ˜¯ç”¨ç¦»æ•£ç‚¹è¿‘ä¼¼ï¼‰ã€‚

---

## 6) å¾—åˆ° APï¼šå¯¹ 101 ä¸ª recall ç‚¹çš„æ’å€¼ precision æ±‚å¹³å‡ï¼ˆè¿‘ä¼¼é¢ç§¯ï¼‰

åœ¨ç±»åˆ« (c)ã€IoU é˜ˆå€¼ (t) ä¸‹ï¼š

$$  
\mathrm{AP}_{c,t}=\frac{1}{101}\sum_{r\in R}\hat p(r)  
\approx \int_{0}^{1}\hat p(r),dr.  
$$

å¾ˆå¤šåº“/è¯´æ˜éƒ½ä¼šæ¦‚æ‹¬ä¸ºï¼šCOCO çš„ AP æ˜¯æŠŠ precision åœ¨ **101 ä¸ª recall ç‚¹**ä¸Šå–å€¼åå¹³å‡ï¼Œå¹¶ä¸”è¿˜ä¼šåœ¨å¤šä¸ª IoU é˜ˆå€¼ä¸Šå†å¹³å‡ã€‚([Medium](https://medium.com/data-science-at-microsoft/how-to-smoothly-integrate-meanaverageprecision-into-your-training-loop-using-torchmetrics-7d6f2ce0a2b3?utm_source=chatgpt.com "How to smoothly integrate MeanAveragePrecision into ..."))

---

## 7) å¾—åˆ° mAPï¼ˆCOCO çš„ä¸»æŒ‡æ ‡ AP@[.50:.95]ï¼‰

COCO æŠ¥å‘Šçš„â€œAPâ€ï¼ˆå¾ˆå¤šè®ºæ–‡ä¹Ÿå« mAPï¼‰æ˜¯ **å…ˆå¯¹ IoU é˜ˆå€¼å¹³å‡ï¼Œå†å¯¹ç±»åˆ«å¹³å‡**ï¼š

$$  
\mathrm{mAP}=\frac{1}{|C|}\sum_{c\in C}\Big(\frac{1}{|T|}\sum_{t\in T}\mathrm{AP}_{c,t}\Big),  
\quad T={0.50,\dots,0.95}.  
$$

æ‰€ä»¥ä½ å¸¸è§çš„ï¼š

- **AP50**ï¼šåªå– (t=0.50) çš„ AP
    
- **AP75**ï¼šåªå– (t=0.75) çš„ AP
    
- **AP@[.50:.95]**ï¼š10 ä¸ªé˜ˆå€¼éƒ½ç®—ï¼Œå†å¹³å‡ï¼ˆä¸»æŒ‡æ ‡ï¼‰
    

è€Œ DETR README é‡Œå†™çš„ â€œ**42 AP on COCO** / AP is computed on COCO 2017 val5kï¼Œå¹¶ä½¿ç”¨ pycocotools è¯„æµ‹â€å°±æ˜¯è¿™ä¸ªæŒ‡æ ‡ä½“ç³»ã€‚([GitHub](https://raw.githubusercontent.com/facebookresearch/detr/main/README.md "raw.githubusercontent.com"))

---

### ä¸€å¥è¯æŠŠé“¾è·¯ä¸²èµ·æ¥

$$  
\boxed{\text{IoU} \xrightarrow[\text{æ¯ç±»ã€æ¯é˜ˆå€¼}]{\text{åŒ¹é…}} \text{TP/FPåºåˆ—}  
\xrightarrow{\text{ç´¯ç§¯}} (P(k),R(k))  
\xrightarrow{\text{101ç‚¹æ’å€¼}} \mathrm{AP}_{c,t}  
\xrightarrow{\text{å¯¹ }t\text{ ä¸ }c\text{ å¹³å‡}} \mathrm{mAP}}  
$$

# æ¨ç†ä»£ç æ”¹è¿›ï¼ˆä¸è¦ä½¿ç”¨é«˜é˜ˆå€¼è¿‡æ»¤ï¼‰
åœ¨æ ‡å‡† COCOeval è¯„æµ‹é‡Œï¼Œä¸€èˆ¬ä¸ä¼šéšæ„è°ƒä¸€ä¸ªâ€œé«˜é˜ˆå€¼â€å»å‰ªæ‰å¤§é‡æ¡†æ¥ä½œå¼Šï¼›å®ƒä¼šåŸºäºé¢„æµ‹çš„ score æ’åºå»ç”» PR æ›²çº¿ï¼Œå¹¶ä¸”è¿˜æœ‰æ¯å›¾æœ€å¤šå–å‰ 100 ä¸ªæ£€æµ‹ï¼ˆmaxDets=100ï¼‰è¿™ç±»è§„åˆ™ã€‚  
ä½†å¦‚æœä½ åœ¨è‡ªå·±çš„ä»£ç é‡Œå…ˆç”¨å¾ˆé«˜çš„ score é˜ˆå€¼æŠŠé¢„æµ‹ç æ‰ï¼Œå†é€å»è¯„æµ‹ï¼Œç¡®å®ä¼šæ”¹å˜ PR æ›²çº¿ï¼Œä»è€Œæ”¹å˜ APï¼ˆé€šå¸¸å¬å›ä¼šä¸‹é™ï¼‰ã€‚

---

å› æ­¤éœ€è¦æ”¹è¿›æ¨ç†ä»£ç ï¼Œç”±åŸå…ˆçš„**é«˜scoreé˜ˆå€¼**æ”¹è¿›ä¸º**ä½scoreé˜ˆå€¼+top-Kè¿‡æ»¤**
## score0é˜ˆå€¼(Ï„)ä¼šä¸ä¼šå½±å“ mAPï¼Ÿ

**æ ‡å‡† COCO mAPï¼ˆAP@[.50:.95]ï¼‰ç†è®ºä¸Šä¸éœ€è¦ä½ æ‰‹åŠ¨è®¾ score é˜ˆå€¼ã€‚**

åŸå› ï¼šCOCOeval ä¼šå¯¹ä½ æäº¤çš„æ‰€æœ‰æ£€æµ‹æŒ‰ score æ’åºï¼Œç­‰ä»·äºâ€œä» $Ï„=+âˆ$ æ…¢æ…¢é™ä½åˆ° $âˆ’âˆ$â€æ‰«ææ•´ä¸ª PR æ›²çº¿ï¼Œæœ€åå¯¹ PR æ›²çº¿ç§¯åˆ†å¾—åˆ° APã€‚

æ‰€ä»¥ï¼š

- å¦‚æœä½ **ä¸äººä¸ºåˆ é¢„æµ‹**ï¼ˆæˆ–åªåšå¾ˆå®½æ¾çš„è¿‡æ»¤ï¼Œæ¯”å¦‚ä¿ç•™å¤§é‡é¢„æµ‹ï¼‰ï¼Œè¯„æµ‹ä¼šè‡ªåŠ¨åˆ©ç”¨ score æ’åºç”Ÿæˆæ•´æ¡ PR æ›²çº¿ã€‚
    
- å¦‚æœä½ åœ¨é€è¯„æµ‹å‰ç”¨äº†ä¸€ä¸ªè¾ƒé«˜çš„ $Ï„$ æŠŠä½åˆ†æ¡†åˆ æ‰äº†ï¼Œç›¸å½“äºæŠŠ PR æ›²çº¿çš„â€œä½é˜ˆå€¼éƒ¨åˆ†â€æˆªæ‰äº†ï¼š
    
    - å¬å›ä¸Šä¸å» â†’ AP å¾€å¾€ä¼š **ä¸‹é™**ï¼ˆå°¤å…¶æ˜¯å¯¹éš¾ä¾‹/å°ç›®æ ‡ï¼‰ã€‚
        
- ä½†æœ‰æ—¶å¦‚æœä½ çš„è¾“å‡ºé‡Œå……æ»¡æä½åˆ†çš„åƒåœ¾æ¡†ï¼Œåˆ æ‰å®ƒä»¬å¯¹ maxDets=100 çš„æˆªæ–­ä¹Ÿè®¸ä¼šæœ‰è½»å¾®å½±å“ï¼›ä¸è¿‡**æ­£ç¡®åšæ³•**é€šå¸¸æ˜¯è®©è¯„æµ‹å·¥å…·å¤„ç†ï¼Œè€Œä¸æ˜¯æ‰‹å·¥å¡æ­»ä¸€ä¸ªå›ºå®š $Ï„$ã€‚


### å¸¸ç”¨æ”¹è¿›ç­–ç•¥ï¼š

#### A. ç›´æ¥é™ä½é˜ˆå€¼ï¼ˆæœ€ç®€å•ï¼‰

æŠŠ Ï„\tauÏ„ ä» 0.9 å…ˆé™åˆ°ï¼š

- **0.5**ï¼ˆé€šå¸¸æ›´å¹³è¡¡ï¼‰
    
- æˆ– **0.3**ï¼ˆæ›´åå¬å›ï¼Œæ¡†ä¼šå¤šä¸€ç‚¹ï¼‰
    

ç»éªŒä¸Š DETR çš„å¾ˆå¤šæ­£ç¡®æ¡†åˆ†æ•°ä¸ä¸€å®šåˆ° 0.9ï¼Œå°¤å…¶æ˜¯å°ç›®æ ‡/é®æŒ¡/è¿œå¤„ç›®æ ‡ã€‚

#### B. ç”¨ top-kï¼ˆæ›´ç¨³å®šï¼‰

å› ä¸º DETR å›ºå®šè¾“å‡º NNN ä¸ª queriesï¼ˆä¾‹å¦‚ 100 ä¸ªï¼‰ï¼Œä½ å¯ä»¥ï¼š

1. å¯¹æ¯ä¸ª query å–â€œé no-object çš„æœ€å¤§ç±»åˆ«æ¦‚ç‡â€å½“ score
    
2. **æŒ‰ score æ’åºå–å‰ kkk**ï¼ˆæ¯”å¦‚ k=100k=100k=100ã€505050ã€202020ï¼‰ï¼Œå†åšå¯è§†åŒ–/ä¸‹æ¸¸ä»»åŠ¡
    

è¿™æ ·ä¸ä¼šå› ä¸ºé˜ˆå€¼è¿‡é«˜è€Œâ€œå…¨æ— â€ï¼Œä¹Ÿä¸ä¼šå› ä¸ºé˜ˆå€¼è¿‡ä½è€Œçˆ†ç‚¸å¼å¢æ¡†ã€‚

## æ”¹è¿›åçš„æ¨ç†ä»£ç 
```python
model.eval()

inputs = processor(images=img, return_tensors="pt").to(DEVICE)
with torch.inference_mode():  # æ¯” no_grad æ›´é€‚åˆçº¯æ¨ç†
    outputs = model(**inputs)

target_sizes = torch.tensor([img.size[::-1]], device=DEVICE)

# â‘  è¯„æµ‹/æƒ³è¦é«˜å¬å›ï¼šé˜ˆå€¼è®¾å¾ˆä½ï¼ˆç”šè‡³ 0.0ï¼‰ï¼Œä¸è¦ç”¨ 0.9
results = processor.post_process_object_detection(
    outputs,
    threshold=0.05,          # å»ºè®®ï¼šè¯„æµ‹ç”¨ 0.0~0.05
    target_sizes=target_sizes
)[0]

# â‘¡ ç”¨ top-k æ§åˆ¶è¾“å‡ºæ•°é‡ï¼ˆCOCO å¸¸ç”¨æ¯å›¾æœ€å¤š 100ï¼‰
top_k = 100
if results["scores"].numel() > top_k:
    idx = results["scores"].topk(top_k).indices
    results = {k: v[idx] for k, v in results.items()}

```
æ ¸å¿ƒå°±æ˜¯ï¼š**åˆ«å†ç”¨ 0.9**ï¼›ç”¨ **è¾ƒä½ threshold ä¿å¬å›**ï¼Œå†ç”¨ **top-k æ§åˆ¶æ•°é‡**ã€‚

# ä½¿ç”¨Pycocotoolè¿›è¡Œè¯„ä»·

## 1) COCO mAP å®˜æ–¹è¯„ä¼°ä»£ç ï¼ˆæ ¸å¿ƒï¼‰
ä½¿ç”¨uvå®‰è£…
```sh
uv add pycocotools
```

ä½¿ç”¨pipå®‰è£…

```bash
pip install pycocotools
```

## 2) ç”¨COCOevalè·‘è¯„æµ‹ï¼ˆbbox mAPï¼‰
```python
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

ann_file = "instances_val2017.json"      # GT
pred_file = "detr_results.json"      # ä½ çš„é¢„æµ‹

cocoGt = COCO(ann_file)
cocoDt = cocoGt.loadRes(pred_file)

cocoEval = COCOeval(cocoGt, cocoDt, iouType="bbox")
# å¯é€‰ï¼šåªè¯„æŸäº›å›¾ç‰‡
# cocoEval.params.imgIds = [397133, 12345, ...]

cocoEval.evaluate()
cocoEval.accumulate()
cocoEval.summarize()

```
è¿™ä¼šè¾“å‡º COCO æ ‡å‡†çš„ï¼š

- AP @[IoU=0.50:0.95 | area=all | maxDets=100]
    
- AP50ã€AP75ã€ä»¥åŠ small/medium/large ç­‰ã€‚[GitHub](https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb?utm_source=chatgpt.com)

å¦‚ä½•åˆ†æmAPç»“æœï¼Œå‚è€ƒ[æ­¤æ–‡ç« ](./mAPç»“æœåˆ†æ.md)
