# 先生成SQL再渲染图表，还是根据图表生成SQL再渲染？
两种方案本质上对应两种“控制点”：

- 方案 A：**先生成 SQL → 拿到结果 → 再决定怎么转化与画图**（SQL 为主，图表为后）
    
- 方案 B：**先确定要画什么图（指标/维度/粒度/排序/TopN/对比口径）→ 反推 SQL 一步到位**（可视化语义为主，SQL 为后）
    

在“Agent 根据自然语言自动产出可视化”这个场景里，整体上 **方案 B 更优**，但落地时最好采用 **B 为主、A 兜底的混合架构**。原因与推荐做法如下。

---

## 为什么“先定图再写 SQL”（方案 B）通常更好

### 1) 可控性与一致性更强

用户提问往往隐含了图表语义：时间趋势、分组对比、占比结构、分布、排名、漏斗等。  
如果你先写 SQL，SQL 的结果形态可能不适合目标图（例如缺少时间粒度、未做 TopN、没有同比/环比口径、没有完整维度枚举导致缺失值），后面强行用 pandas/py 处理会让链路越来越“魔法”。

方案 B 会先把“要什么图、X/Y 是什么、维度是什么、度量是什么、粒度是什么”定下来，然后 SQL 输出就天然贴合 pyecharts 的输入结构，渲染稳定。

### 2) 性能更好、成本更低

“先 SQL 再处理”常见问题是 SQL 抓了过多数据，后面在 Python 做聚合/排序/TopN/填补，数据量大时会明显拖慢。  
方案 B 倾向把 **聚合、过滤、TopN、时间粒度** 下推到数据库，一次返回“小而对”的结果集。

### 3) 更容易做质量校验与自动修复

你可以为每种图表定义 **输出 schema（列名、类型、行数约束、是否允许空值）**。  
例如折线图期望：`[time, metric]` 或 `[time, series, metric]`；饼图期望：`[category, value]`。  
当 SQL 返回不符合 schema 时，Agent 可以明确地“知道哪里不对”，更容易自动改 SQL（加 group by、补维度、改粒度等）。

### 4) 口径解释更清晰

业务用户经常追问：“这个数怎么来的？”  
如果图表语义驱动 SQL，你可以输出一段结构化解释：指标定义、过滤条件、时间范围、分组维度、排序与截断规则。这比“先跑出一堆数据再解释怎么加工”更可信。

---

## 什么时候“先 SQL 再图表”（方案 A）反而更合适

方案 A 并非不可用，适合以下情况：

1. **探索式分析 / 不确定图表类型**：用户问得很泛（“帮我看看最近情况”），先取一个概览数据再决定图。
    
2. **强制复用现成 SQL 或视图**：企业里往往有既定宽表/视图/指标层，SQL 形态固定，图表只是消费。
    
3. **需要做复杂二次特征**：比如分箱、异常检测、复杂衍生指标，数据库做很痛苦，Python 更合适。
    
4. **数据库能力受限**：某些 OLTP/权限限制不允许复杂窗口函数/CTE。
    

因此更现实的结论是：**方案 B 做主路径，方案 A 做 fallback**。

---

## 推荐的“混合架构”（最稳）

### Step 0：意图解析成“可视化规格”（Chart Spec）

先把用户问题解析成一个中间表示（强烈建议做成 JSON）：

- 图表类型：line/bar/pie/scatter/heatmap/table…
    
- 时间范围：最近 30 天 / 本月 / 自定义
    
- 时间粒度：day/week/month
    
- 维度（group by）：地区/渠道/品类
    
- 度量（metric）：订单数/GMV/转化率
    
- 过滤条件：渠道=XX，国家=CN…
    
- 排序与截断：Top 10
    
- 是否需要对比：同比/环比/去年同月
    
- 空值处理策略：补 0/补齐时间序列
    

这个 Chart Spec 一旦确定，后面的 SQL 和 pyecharts 就都围绕它来。

### Step 1：由 Spec 生成 SQL（数据库完成主要聚合）

- 尽量输出“最终可画图”的窄表结果
    
- 对于时间序列，建议在 SQL 或后处理里补齐缺失时间点（视数据库能力决定）
    

### Step 2：执行 SQL 并做“结果校验”

校验点包括：

- 列是否齐全、类型是否合理（time 是否可解析）
    
- 行数是否异常（0 行、1 行、百万行）
    
- 是否存在重复 key（time+series 重复）
    
- 是否存在 NaN/NULL 超标
    

### Step 3：如不满足 schema，触发“SQL 修复循环”（有限轮次）

例如：

- 折线图只有一列 value：说明少了 time 字段或 group by
    
- 返回行数过大：说明忘了聚合/时间粒度
    
- 饼图返回 time+value：说明图表类型选择错误或 spec 需要调整
    

### Step 4：渲染 pyecharts

pyecharts 本质是消费结构化数组，保证结果 schema 稳定后，渲染会非常稳。

---

## 关键实现建议（决定你系统是否“像个产品”）

1. **把“图表 spec”作为第一等公民**  
    不要让“SQL 字符串”成为你的核心中间产物。SQL 是实现细节；Spec 才是产品语义。
    
2. **图表 ↔ 输出 schema 映射要固定**  
    为每种图定义期望列，例如：
    

- Line：`time, value` 或 `time, series, value`
    
- Bar：`category, value` 或 `category, series, value`
    
- Pie：`category, value`
    
- Scatter：`x, y`（可选 series）  
    这样才能自动检测并修复。
    

3. **限制自由度，减少幻觉空间**
    

- 只允许从“可用维度/指标字典”里选字段（metadata / semantic layer）
    
- 统一时间字段与时区（你在 Asia/Tokyo 就要明确落库与展示时区）
    
- 对 TopN、排序、过滤做严格模板化
    

4. **把“数据量控制”做成硬约束**  
    默认：
    

- 聚合后行数上限（例如 5,000）
    
- 时间序列默认粒度（例如超过 180 天自动按周）
    
- 返回列数上限（避免宽表）
    

---

## 结论

- 作为主方案：**先确定图表与数据语义（Spec）→ 再生成 SQL 一步到位（方案 B）**，更稳定、可解释、性能更好。
    
- 作为兜底：保留 **先 SQL 再决定图（方案 A）** 的能力，用于探索式/不确定意图/受限 SQL 场景。
    
- 最佳实践：**B 主路径 + 结果 schema 校验 + 有限轮次自动修复 + A fallback**。
    

# 参考标准流程

## 推荐流程（可直接按模块实现）

### 1) NL → ChartSpec（语义规格层）

目标：把自然语言压缩成**可执行、可校验**的结构化规格。

ChartSpec 至少包含：

- `task_type`: chart / table / insight
    
- `chart_type`: line / bar / pie / scatter / heatmap…
    
- `dimensions`:（0~2 个）分组字段 + 角色（x/series/category）
    
- `measures`:（1~N 个）指标（sum/count/avg/ratio…）
    
- `time`: 时间字段、范围、粒度（day/week/month）、时区、是否补齐
    
- `filters`: 条件（枚举/范围/模糊）
    
- `order_by` + `top_n`
    
- `compare`: yoy/mom/period_over_period（可选）
    
- `constraints`: 行数上限、是否允许空、单位、精度等
    

关键建议：  
**ChartSpec 要“保守”**，宁可缺省一些字段也不要胡编；但一旦给出字段，就要能被后续校验。

---

### 2) Schema / Semantic Layer 检索（表字段混合检索）

你说的“混合检索”非常重要，但建议把它拆成两层：

- **物理层（Physical Schema）**：库/表/字段/类型/主外键/分区/索引
    
- **语义层（Semantic Dictionary）**：指标定义（GMV=SUM(pay_amount)）、口径、维度含义、常用过滤枚举、时间字段约定
    

检索输出不要只给“候选字段”，还要给：

- 字段类型（数值/时间/枚举/文本）
    
- 基数/分布（高基数维度要谨慎上图）
    
- 建议聚合方式（sum/avg/distinct count）
    
- 关联路径（join graph）
    

这一步的作用是：**约束 ChartSpec 的可实现性**，并为 SQL 生成提供可选空间。

---

### 3) ChartSpec × 检索结果 → QuerySpec（查询规格层）

建议在生成 SQL 之前再加一个 QuerySpec（或 Plan）层，用来“定案”：

- 使用哪些表（事实表/维表）
    
- join 路径与 join key
    
- 过滤下推策略
    
- 时间处理策略（分区裁剪、时区转换）
    
- 指标计算方式（直接聚合/窗口函数/子查询）
    
- 输出 schema（给后续校验用）
    

这样做的好处：  
SQL 生成只是把 QuerySpec **模板化渲染**，而不是让模型自由写 SQL；可控性会高很多。

---

### 4) SQL 生成（模板化优先）

实现上建议：

- 80% 场景走模板（group by、time bucket、topn、rank、yoy/mom）
    
- 剩余 20% 才允许“自由 SQL”，并且必须通过强校验
    

并且强制带：

- `LIMIT`（或数据库等价物）
    
- 明确列别名（统一为 `x`, `series`, `y` 或 `time`, `category`, `value`）
    
- 可复用的 CTE 分层（base → agg → final）
    

---

### 5) 执行 + 结果校验（Schema Validation）

这是循环修复的“触发器”。校验维度至少包括：

**结构校验**

- 列是否齐全（符合 chart_type 的输出 schema）
    
- 列类型是否可解析（time 是否能转 datetime）
    
- 是否存在重复 key（time+series 重复会导致折线异常）
    

**统计校验**

- 行数是否过大/过小（0 行、1 行、>5000 行）
    
- 类别数是否过多（饼图/柱图类别>30 通常不可读）
    
- 数值是否全为 0 / 全为 NULL（口径或过滤错误）
    

**业务校验（可选）**

- 指标单位/范围合理性（例如转化率应在 [0,1] 或 [0,100]）
    

---

### 6) 循环修复（SQL 修复优先，必要时回退到 Spec 修复）

你的思路是“依赖前几步上下文不断调整”，完全可以。但建议你明确修复优先级：

1. **SQL 级修复**（最小改动）
    
    - 补 group by / 改时间粒度 / 加 topn / 修 join / 修过滤
        
2. **QuerySpec 级修复**
    
    - 换事实表/换指标定义/调整 join 路径
        
3. **ChartSpec 级修复**（语义变更，必须可解释）
    
    - 图表类型不匹配（例如“占比”却生成了折线）
        
    - 用户意图本身更适合 table 而不是 chart
        

并且强制：

- **最大迭代轮次**（例如 2~4 次）
    
- 每轮输出一个“修复理由”供日志与调试（不一定展示给用户）
    

---

## 这个流程里最关键的两点改进建议

### A) “相互约束”要有明确的决策规则

否则会变成模型在 Spec 和 SQL 之间来回漂移。建议你定义硬规则，例如：

- pie 必须：1 个维度 + 1 个度量，且无 time
    
- line 必须：time + 度量（可选 series），time 粒度必须存在
    
- top_n 仅在 category cardinality 高时启用
    
- 若 time_range > 180 天且粒度=day，自动升为 week（除非用户明确要求 daily）
    

这些规则越明确，系统越像“产品”，越不像“聊天”。

### B) Schema/语义层要尽量“标准化”，减少模型猜字段

如果没有指标层/维度字典，模型只能猜字段含义，循环修复会变得昂贵且不稳定。最少也要有：

- 每个指标的 SQL 定义
    
- 每个维度的字段映射（含维表 join）
    
- 推荐的默认时间字段
    

---

## 最终判断

你提出的流程“ChartSpec → 混合检索 → 约束生成 SQL → 执行校验 → 循环修复”不仅可行，而且是推荐路线。  
如果你希望稳定性再上一个台阶，我建议你在 SQL 前加一个 QuerySpec/Plan 层，并把修复机制做成“先 SQL 后 Spec”的分层回退。

# ChartSpec / QuerySpec 字段参考
下面是一套“可直接落地”的 **ChartSpec / QuerySpec 字段定义**（偏工程化、可校验、适配 NL→SQL→pyecharts）。你可以先按这个最小可用版本实现，后续再扩展。

---

## ChartSpec（意图与可视化语义层）

建议把 ChartSpec 设计为“用户意图的最终解释”，尽量不出现具体表名/字段名（但允许出现已对齐的语义字段名）。

```json
{
  "spec_version": "1.0",
  "task_type": "chart",
  "title": "",
  "description": "",

  "chart": {
    "type": "line",
    "subtype": null,
    "stack": false,
    "smooth": false,
    "orientation": "vertical"
  },

  "axes": {
    "x": { "role": "time", "field": "order_date", "format": null },
    "y": [{ "role": "measure", "field": "gmv", "unit": "CNY", "format": "0,0.00" }],
    "series": { "role": "dimension", "field": null }
  },

  "dimensions": [
    {
      "name": "region",
      "role": "series",
      "cardinality_hint": null,
      "limit": null
    }
  ],

  "measures": [
    {
      "name": "gmv",
      "aggregation": "sum",
      "expr": null,
      "format": "0,0.00",
      "unit": "CNY"
    }
  ],

  "time": {
    "enabled": true,
    "field": "order_time",
    "range": { "type": "relative", "value": 30, "unit": "day" },
    "grain": "day",
    "timezone": "Asia/Tokyo",
    "fill_missing": true,
    "fill_method": "zero"
  },

  "filters": [
    {
      "field": "channel",
      "op": "in",
      "value": ["app", "web"]
    }
  ],

  "compare": {
    "enabled": false,
    "type": null,
    "baseline": null
  },

  "order": [
    { "by": "gmv", "direction": "desc" }
  ],
  "topn": { "enabled": false, "n": 10, "by": "gmv" },

  "output": {
    "expected_schema": "time_series",
    "max_rows": 5000,
    "max_categories": 30
  },

  "confidence": {
    "intent": 0.0,
    "mapping": 0.0,
    "notes": ""
  }
}
```

### ChartSpec 字段说明（关键点）

- `chart.type`：line/bar/pie/scatter/heatmap/table 等
    
- `axes`：明确 x/y/series 对应什么（非常利于后续校验与渲染）
    
- `dimensions/measures`：语义字段（如“gmv”“region”），不要直接绑定物理字段
    
- `time`：时间范围与粒度是可视化里最关键的歧义来源，单独成块
    
- `filters`：统一成三元组（field/op/value），便于模板化下推
    
- `output`：强约束（行数/类别数）用于自动降采样、自动 topn、自动升粒度
    
- `confidence`：日志与调试用，不影响执行
    

---

## QuerySpec（查询规划与可执行层）

QuerySpec 是“把 ChartSpec 落到数据库可执行计划”的结果，必须包含表、字段、join、聚合、最终输出列别名等。

```json
{
  "spec_version": "1.0",

  "datasource": {
    "dialect": "postgres",
    "catalog": null,
    "schema": "public"
  },

  "semantic_bindings": {
    "order_time": { "table": "fact_orders", "column": "created_at", "type": "timestamp" },
    "gmv": { "table": "fact_orders", "expr": "pay_amount", "type": "number" },
    "region": { "table": "dim_region", "column": "region_name", "type": "string" },
    "channel": { "table": "fact_orders", "column": "channel", "type": "string" }
  },

  "from": {
    "base_table": { "name": "fact_orders", "alias": "o" },
    "joins": [
      {
        "type": "left",
        "table": { "name": "dim_region", "alias": "r" },
        "on": [{ "left": "o.region_id", "op": "=", "right": "r.id" }]
      }
    ]
  },

  "time": {
    "field": "o.created_at",
    "timezone": "Asia/Tokyo",
    "range": { "start": "2025-12-15", "end": "2026-01-14" },
    "grain": "day",
    "bucket_expr": "date_trunc('day', o.created_at)"
  },

  "select": [
    { "expr": "date_trunc('day', o.created_at)", "alias": "x", "type": "time" },
    { "expr": "sum(o.pay_amount)", "alias": "y", "type": "number" },
    { "expr": "r.region_name", "alias": "series", "type": "string", "optional": true }
  ],

  "where": [
    { "expr": "o.created_at >= :start_time" },
    { "expr": "o.created_at < :end_time" },
    { "expr": "o.channel in (:channels)" }
  ],

  "group_by": ["x", "series"],
  "having": [],

  "order_by": [{ "expr": "x", "direction": "asc" }],
  "limit": 5000,

  "post_processing": {
    "fill_missing_time": true,
    "fill_value": 0,
    "topn": null,
    "pivot": null
  },

  "output_schema": {
    "type": "time_series",
    "columns": [
      { "name": "x", "role": "x", "type": "time" },
      { "name": "series", "role": "series", "type": "string", "optional": true },
      { "name": "y", "role": "y", "type": "number" }
    ],
    "primary_key": ["x", "series"]
  },

  "params": {
    "start_time": "2025-12-15T00:00:00+09:00",
    "end_time": "2026-01-15T00:00:00+09:00",
    "channels": ["app", "web"]
  }
}
```

### QuerySpec 设计要点

- `semantic_bindings`：语义字段 → 物理字段/表达式 的绑定清单（便于溯源与修复）
    
- `from.joins`：显式 join graph，避免模型“凭空 join”
    
- `time.bucket_expr`：把时间分桶表达式固化，SQL 模板直接渲染
    
- `select`：强制统一别名（推荐 `x / series / y`），pyecharts 适配最轻
    
- `post_processing`：明确哪些事情留给 Python（补齐、pivot、topn）
    
- `output_schema.primary_key`：用于检测重复点（折线图常见错误）
    

---

## 最小输出 schema（建议你固定几种）

你后续的“结果校验 + 修复”会非常依赖它。建议至少内置这些：

1. `time_series`
    

- 列：`x(time)`, `y(number)` 或 `x(time)`, `series(string)`, `y(number)`
    

2. `categorical`（柱/饼）
    

- 列：`x(category)`, `y(number)` 或 `x(category)`, `series`, `y`
    

3. `xy`（散点）
    

- 列：`x(number|time)`, `y(number)`, 可选 `series`
    

4. `table`
    

- 列任意，但要限制 `max_rows/max_cols`
    

---

## 建议的“字段枚举”标准（便于模板化）

- `aggregation`: `sum | count | count_distinct | avg | min | max`
    
- `filter.op`: `= | != | in | not_in | > | >= | < | <= | between | like`
    
- `time.grain`: `hour | day | week | month | quarter | year`
    
- `join.type`: `inner | left | right`
    
- `chart.type`: `line | bar | pie | scatter | heatmap | table`
    

---

## 你可以立刻用的实现策略（简短但关键）

- **ChartSpec 负责“你要画什么”**（维度/指标/时间粒度/TopN）
    
- **QuerySpec 负责“怎么查到”**（表、join、表达式、别名、limit）
    
- SQL 生成只做：`QuerySpec -> SQL string + params`
    
- 循环修复以 **output_schema 校验失败** 为触发，优先改 QuerySpec（小步），必要时回退改 ChartSpec（语义级）
    

---

如果你希望下一步更快落地，我建议你接下来补两份“配套资产”：

1. 一张 **chart_type → expected_schema → 校验规则** 的映射表
    
2. 一张 **常见失败类型 → QuerySpec 修复动作** 的策略表（例如：行数过大→升粒度/加 topn/加 limit；缺列→补 group by 或补 join）
    

